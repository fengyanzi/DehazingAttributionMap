# Dehazing Attribution Map (ÂéªÈõæÂΩíÂõ†Âõæ)

This repository provides the official implementation of the **Dehazing Attribution Map** section from the **CVPR2025** paper: [Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images](https://arxiv.org/abs/2504.09621).

- üîç Visualizing image regions critical for dehazing model decisions.
- üìä Quantifying contributions of global context information to dehazing effectiveness.
- ‚öôÔ∏è Enhancing interpretability of deep learning-based dehazing models.

---

*The source code for the proposed **DehazeXL** model is available at [GitHub](https://github.com/CastleChen339/DehazeXL). The mini version of the proposed dataset **8Kdehaze** can be accessed here: [Modelscope](https://www.modelscope.cn/datasets/fengyanzi/8kdehaze_mini/) | [Hugging Face](https://huggingface.co/datasets/fengyanzi/8KDehaze_mini) | [BaiduCloud](https://pan.baidu.com/s/1ZVipOYnTR-M_xG5FZNtZPQ?pwd=4321) | [AliCloud](https://www.alipan.com/s/7AVat72s4Sk).

For the full version of **8Kdehaze**, visit: [BaiduCloud](https://pan.baidu.com/s/1-z7h-BLV7BxNg4Qp6Hi5uQ?pwd=4321).

---

![LAM Example Image](./docx/main.png)

### Quick Start üöÄ

Before using this project, make sure all necessary dependencies are installed. You can install them via:

```bash
pip install -r requirements.txt
```

Commonly used Python libraries for deep learning included:
```plaintext
numpy
torch
opencv-python
torchvision
Pillow
matplotlib
scipy
tqdm
```

To run the project (which includes DehazeXL):

1. Download test weights from: [GitHub](https://github.com/fengyanzi/DehazingAttributionMap/releases/tag/weight)
2. Place the weights in `./model/weights/weightforDAMtest.pth`
3. Execute:

```bash
python Dehaze_Demo.py
```

### Testing Your Own Model üß™

1. Place the hazy and clear images you wish to test in the `./clear/dehaze` folder.
2. Put your dehazing model and its weights in the `model` folder.
3. Modify the following snippet in the `Dehaze_Demo.py` file to load your model and set parameters accordingly.

```python
from model.dehaze_backbones.xt.decoders.decoder_pre import xT as DehazeXL
    # Load your own model
    model = DehazeXL().to("cuda").eval()

    modelpath = r'model/weights/weightforDAMtest.pth'
    cloudimgpath = r'data/dehaze/test1.png'
    clearingpath = r'data/dehaze/clear1.png'
    save_path = './results/test.png'
```

### Parameter Description ‚öôÔ∏è

- `--modelpath`: Path to the model weights.
- `--imgpath`: Path to the test image.
- `--w`: X-coordinate of the selected area.
- `--h`: Y-coordinate of the selected area.
- `--window_size`: Size of the selected area.
- `--fold`: Number of path integral steps. Higher values yield results closer to the true value. Default is 50, not recommended to modify.
- `--sigma`: Path integral parameter, not recommended to modify.
- `--l`: Path integral parameter, not recommended to modify.
- `--alpha`: Alpha value for blending.
- `--zoomfactor`: Image zoom factor, default is 1. If your GPU configuration is low, consider setting it to 4.
- `--kde`: Whether to use KDE for visualization (requires high computational power).
- `--output_dir`: Output directory for images.
- `--betterview`: Improves the visibility of attribution maps.

## Code References üìö

This project was inspired by and references the following open-source projects. We appreciate their contribution to the community:
- [LAM](https://github.com/fengyanzi/Local-Attribution-Map-for-Super-Resolution)

## Citation üìù

If you use DAM, please cite:
```bibtex
@article{chen2025tokenize,
  title={Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images},
  author={Chen, Jiuchen and Yan, Xinyu and Xu, Qizhi and Li, Kaiqi},
  journal={arXiv preprint arXiv:2504.09621},
  year={2025}
}
```



<!-- # Dehazing Attribution Map (ÂéªÈõæÂΩíÂõ†Âõæ)
This repository is an official implementation of theÂéªÈõæÂΩíÂõ†ÂõæÈÉ®ÂàÜ of the paper  [Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images](https://arxiv.org/abs/2504.09621)

- üîç ÂèØËßÜÂåñÂéªÈõæÊ®°ÂûãÂÜ≥Á≠ñ‰æùËµñÁöÑÂõæÂÉèÂå∫Âüü
- üìä ÈáèÂåñÂÖ®Â±Ä‰∏ä‰∏ãÊñá‰ø°ÊÅØÂØπÂéªÈõæÊïàÊûúÁöÑË¥°ÁåÆ
- ‚öôÔ∏è ÊîπÂñÑÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂéªÈõæÊ®°ÂûãÂèØËß£ÈáäÊÄß

---
*The source code ofËÆ∫ÊñáÊâÄÊèêÂá∫ DehazeXL are available at [https://github.com/CastleChen339/DehazeXL](https://github.com/CastleChen339/DehazeXL).
ËÆ∫ÊñáÊâÄÊèêÂá∫Êï∞ÊçÆÈõÜ8KdehazeÂèØ‰ª•Âú®‰ª•‰∏ãËé∑ÂæóThe mini version of 8Kdehaze was released: [Modelscope](https://www.modelscope.cn/datasets/fengyanzi/8kdehaze_mini/) [Hugging Face](https://huggingface.co/datasets/fengyanzi/8KDehaze_mini)  [BaiduCloud](https://pan.baidu.com/s/1ZVipOYnTR-M_xG5FZNtZPQ?pwd=4321)   [AliCloud](https://www.alipan.com/s/7AVat72s4Sk)

The Full version of 8Kdehaze:  [BaiduCloud](https://pan.baidu.com/s/1-z7h-BLV7BxNg4Qp6Hi5uQ?pwd=4321)

---

![LAM Example Image](./docx/main.png) 

### Quick Start 


Âú®‰ΩøÁî®ËØ•È°πÁõÆ‰πãÂâçÔºåËØ∑Á°Æ‰øùÂ∑≤ÂÆâË£ÖÊâÄÊúâÂøÖË¶ÅÁöÑ‰æùËµñÂ∫ì„ÄÇ‰Ω†ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£Ö‰æùËµñÔºö
```bash
pip install -r requirements.txt

```

ÂÖ∂‰∏≠Âè™ÂåÖÂê´‰∏Ä‰∫õÂ∏∏ËßÅÁöÑÊ∑±Â∫¶Â≠¶‰π†pythonÂ∫ìÔºö
```plaintext
numpy
torch
opencv-python
torchvision
Pillow
matplotlib
scipy
tqdm
```


Ë¶ÅËøêË°åÊú¨È°πÁõÆ
Êú¨È°πÁõÆÂÜÖÁΩÆDehazeXL
ÊµãËØïÊùÉÈáçÂèØ‰ª•‰ªé‰ª•‰∏ã‰ΩçÁΩÆËé∑ÂæóÔºöhttps://github.com/fengyanzi/DehazingAttributionMap/releases/tag/weight
È¶ñÂÖàËØ∑‰∏ãËΩΩÊùÉÈáçÂπ∂ÊîæÁΩÆÂú®./model/weights/weightforDAMtest.pth

To run the project, execute:

ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö

```bash
python Dehaze_Demo.py
```


### ÊµãËØïËá™Â∑±ÁöÑÊ®°Âûã

1. Place the ÊúâÈõæÂíåÊó†ÈõæÁöÑimages to be tested in the `„ÄÇ/clear/dehaze` folder. 
2. Place the dehaze model and its weights in the `model` folder. 
3. Modify the following code in the `Dehaze_Demo.py` file to load your model and configure parameters.

```python
from model.dehaze_backbones.xt.decoders.decoder_pre import xT as DehazeXL
    # Load your own model
    model = DehazeXL().to("cuda").eval()

    modelpath = r'model/weights/weightforDAMtest.pth'
    cloudimgpath = r'data/dehaze/test1.png'
    clearingpath = r'data/dehaze/clear1.png'
    save_path = './results/test.png'
```

### Parameter Description ÂèÇÊï∞ËØ¥Êòé

- `--modelpath`: Path to the model weights. Ê®°ÂûãÊùÉÈáçË∑ØÂæÑ„ÄÇ
- `--imgpath`: Path to the test image. ÊµãËØïÂõæÂÉèË∑ØÂæÑ„ÄÇ
- `--w`: The x-coordinate of the selected area. ÈÄâÊã©Âå∫ÂüüÁöÑ x ÂùêÊ†á„ÄÇ
- `--h`: The y-coordinate of the selected area. ÈÄâÊã©Âå∫ÂüüÁöÑ y ÂùêÊ†á„ÄÇ
- `--window_size`: The size of the selected area. Âå∫ÂüüÂ§ßÂ∞è„ÄÇ
- `--fold`: The number of path integral steps. Higher values are closer to the true value. Default is 50, not recommended to modify. Ë∑ØÂæÑÁßØÂàÜÊ≠•Êï∞ÔºåË∂äÈ´òË∂äÊé•ËøëÁúüÂÆûÂÄºÔºåÈªòËÆ§ 50Ôºå‰∏çÂª∫ËÆÆ‰øÆÊîπ„ÄÇ
- `--sigma`: Path integral parameter, not recommended to modify. Ë∑ØÂæÑÁßØÂàÜÂèÇÊï∞Ôºå‰∏çÂª∫ËÆÆ‰øÆÊîπ„ÄÇ
- `--l`: Path integral parameter, not recommended to modify. Ë∑ØÂæÑÁßØÂàÜÂèÇÊï∞Ôºå‰∏çÂª∫ËÆÆ‰øÆÊîπ„ÄÇ
- `--alpha`: Alpha value for blending. Ê∑∑ÂêàÊó∂ÁöÑ alpha ÂÄº„ÄÇ
- `--zoomfactor`: ÂõæÂÉèÊîæÂ§ßÂõ†Â≠êÔºåÈªòËÆ§1ÔºåÂ¶ÇÊûú‰Ω†ÁöÑÁîµËÑëGPUÈÖçÁΩÆËæÉ‰ΩéÔºåÂèØÈÖåÊÉÖËÆæÁΩÆ‰∏∫4
- `--kde`: Whether to use KDE for visualization (requires high computational power). ÊòØÂê¶‰ΩøÁî® KDE ËøõË°åÂèØËßÜÂåñÔºàÂØπÁîµËÑëÊÄßËÉΩË¶ÅÊ±ÇËæÉÈ´òÔºåÊó∂Èó¥ËæÉÈïøÔºâ„ÄÇ
- `--output_dir`: Output image directory. ËæìÂá∫ÂõæÁâáÁõÆÂΩï„ÄÇ
- `--betterview`: ÊîπÂñÑÂΩíÂõ†ÂõæÂèØËßÜÊÄß




## Code References ‰ª£Á†ÅÁºñÂÜôÂèÇËÄÉ

Êú¨È°πÁõÆÂú®ÂºÄÂèëËøáÁ®ã‰∏≠ÂèÇËÄÉ‰∫Ü‰ª•‰∏ãÂºÄÊ∫êÈ°πÁõÆÂπ∂ÂèóÂêØÂèëÔºåÊÑüË∞¢‰ªñ‰ª¨ÂØπÂºÄÊ∫êÁ§æÂå∫ÁöÑË¥°ÁåÆÔºö
- [LAM](https://github.com/fengyanzi/Local-Attribution-Map-for-Super-Resolution)

## Citation ÂºïÁî®

If you use DAM, please cite:
Âú®‰ΩøÁî® DAM Êó∂ÔºåËØ∑ÂºïÁî®‰ª•‰∏ãÊñáÁ´†,ËØöÊåöÊÑüË∞¢Ôºö

```bibtex
@article{chen2025tokenize,
  title={Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images},
  author={Chen, Jiuchen and Yan, Xinyu and Xu, Qizhi and Li, Kaiqi},
  journal={arXiv preprint arXiv:2504.09621},
  year={2025}
}
```
 -->
